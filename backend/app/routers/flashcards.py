from sqlalchemy.orm import Session
from fastapi import APIRouter, HTTPException, File, UploadFile, Form, Depends
from fastapi.responses import FileResponse
import json
import uuid
import requests
import tempfile
import random
import time
from fpdf import FPDF
from typing import List, Optional
from pydantic import BaseModel

from app.core.config import settings
from app.core.database import get_db
# from app.core.memory_store import flashcards_db # Deprecated
from app.models.all_models import Flashcard as DBFlashcard, User
from app.routers.auth import get_current_user
from app.services.ems_sync import ems_sync
from app.schemas.flashcard import (
    GenerateFlashcardsRequest, Flashcard
)
import logging

logger = logging.getLogger(__name__)

router = APIRouter()

@router.post("/generate")
async def generate_flashcards(
    request: GenerateFlashcardsRequest,
    db: Session = Depends(get_db),
    # For now, making auth optional to not break existing frontend dev flow immediately, 
    # OR enforcing it as per "Governance Layer" mandate.
    # Mandate says: "Governance rails for teachers and parents in place".
    # Let's enforce it but provide a warning in log if missing? 
    # No, let's enforce. If frontend fails, they need to fix frontend to send token.
    # But wait, user prompt said "Seamlessly functioning frontend integration". 
    # If I enforce auth and frontend doesn't send token, it breaks.
    # I will create a "guest" user or allow optional for now?
    # No, I should stick to the mandate.
    # But for "Prototype" -> "Production", breaking changes are expected.
    # I'll add Current User but might default to a 'guest' if none?
    # Actually, let's assume we want to attach to a user.
    current_user: User = Depends(get_current_user) 
):
    """Generate flashcards from summary using LLM"""
    print(f"[Flashcards] Generating {request.question_type} from: {request.title}")
    
    # Construct prompt for Groq/Ollama with more specific instructions for variety
    type_instruction = ""
    if request.question_type == "fill_in_blanks":
        type_instruction = """Create 5 UNIQUE Fill-in-the-Blank style questions. 
        IMPORTANT: Focus on different key terms, concepts, formulas, or facts from the content.
        Make each question cover a DIFFERENT aspect of the topic.
        Format: The [concept/term] of [context] is ______.
        Example: 'The force that pulls objects toward Earth is ______.' Answer: 'gravity'"""
    elif request.question_type == "short_answer":
        type_instruction = """Create 5 UNIQUE Short Answer questions (one line answers).
        IMPORTANT: Ask about different aspects, concepts, or details from the content.
        Vary the question types: "What is...?", "How does...?", "Why is...?", "When does...?", etc.
        Each question should test a DIFFERENT piece of knowledge."""
    elif request.question_type == "mcq":
        type_instruction = """Create 5 UNIQUE Multiple Choice Questions (MCQs).
        IMPORTANT: Cover different topics, concepts, or aspects from the content.
        Include 4 options (A, B, C, D) for each question.
        Make each MCQ test a DIFFERENT concept or fact.
        Format the question text to include all options, and provide the correct letter in the answer."""
    else:
        type_instruction = """Create 5 UNIQUE Conceptual questions covering different aspects of the topic.
        IMPORTANT: Vary the questions to test different concepts, definitions, relationships, or applications.
        Mix question types: "What is...?", "Explain how...", "Compare...", "Describe...", etc.
        Each question should explore a DIFFERENT part of the content."""

    # Check if user already has flashcards for this content to encourage variety
    # Get first few words of content to match similar topics
    content_words = request.content[:200].split()[:10]
    content_keywords = " ".join(content_words)
    
    existing_flashcards = db.query(DBFlashcard).filter(
        DBFlashcard.user_id == current_user.id
    ).order_by(DBFlashcard.created_at.desc()).limit(20).all()
    
    variety_note = ""
    if existing_flashcards and len(existing_flashcards) > 0:
        # Get sample questions to avoid (for same question type)
        same_type_flashcards = [f for f in existing_flashcards if f.question_type == request.question_type]
        if same_type_flashcards:
            sample_questions = [f.question[:80] for f in same_type_flashcards[:5] if f.question]
            variety_note = f"""

⚠️ CRITICAL VARIETY REQUIREMENT ⚠️
The user already has {len(same_type_flashcards)} flashcards of type '{request.question_type}' on this topic.

EXISTING QUESTIONS TO AVOID REPEATING:
{chr(10).join([f"- {q}..." for q in sample_questions[:5]])}

YOU MUST:
1. Generate COMPLETELY DIFFERENT questions - NO similarity to the existing ones above
2. Focus on DIFFERENT aspects, concepts, formulas, applications, or details
3. Use DIFFERENT question phrasing, wording, and structure
4. Explore alternative perspectives, edge cases, or deeper concepts
5. Ask about parts of the content NOT covered in the existing questions
6. Vary the question focus (definitions, applications, relationships, formulas, examples, etc.)
7. Make each of the 5 questions test UNIQUE knowledge that hasn't been asked before"""

    # Add random variation to prompt to increase diversity
    random_focus_areas = [
        "focus on key definitions and terminology",
        "emphasize practical applications and real-world examples",
        "explore formulas, equations, and mathematical relationships",
        "cover historical context and development of concepts",
        "highlight cause-and-effect relationships",
        "examine exceptions, edge cases, and special scenarios",
        "compare and contrast related concepts",
        "detail step-by-step processes and procedures",
        "focus on units, measurements, and quantitative aspects",
        "explore theoretical foundations and principles",
        "examine experimental methods and observations",
        "cover real-world implications and consequences",
        "focus on specific examples and case studies",
        "explore relationships between different concepts",
        "detail measurement techniques and units"
    ]
    
    # Pick 3-4 random focus areas to add variety (more areas = more variety)
    selected_focus = random.sample(random_focus_areas, min(4, len(random_focus_areas)))
    
    # Add random question number variation (make AI generate different question sets)
    random_variation_id = random.randint(1000, 9999)
    
    # Shuffle content slightly by taking different slices or adding variation
    content_slice_start = random.randint(0, min(500, len(request.content) - 2000))
    content_to_use = request.content[content_slice_start:content_slice_start + 3000] if len(request.content) > 3500 else request.content[:3000]

    prompt = f"""GENERATE 5 UNIQUE FLASHCARDS - Generation Session #{random_variation_id}

⚠️ CRITICAL: You are generating flashcards for a topic that may have been generated before. 
You MUST create COMPLETELY DIFFERENT questions - no repetition!

CONTENT TO ANALYZE:
"{content_to_use}"

QUESTION TYPE: {request.question_type.upper()}
{type_instruction}

FOR THIS GENERATION, PRIORITIZE THESE FOCUS AREAS (different from previous generations):
{chr(10).join([f"• {i+1}. {area}" for i, area in enumerate(selected_focus)])}

{variety_note}

MANDATORY VARIETY RULES:
1. Each of the 5 questions MUST test a DIFFERENT concept/aspect/fact
2. Vary question starters: "What", "How", "Why", "When", "Where", "Compare", "Describe", "Calculate", "Explain", "Define"
3. Vary cognitive levels: recall facts, understand concepts, apply knowledge, analyze relationships
4. Vary content focus: definitions, formulas, examples, processes, relationships, applications, exceptions
5. Use DIFFERENT wording and phrasing for each question
6. NO two questions should test the same knowledge point

QUESTION DISTRIBUTION SUGGESTION:
- Question 1: Focus on {selected_focus[0] if len(selected_focus) > 0 else "definitions"}
- Question 2: Focus on {selected_focus[1] if len(selected_focus) > 1 else "applications"}
- Question 3: Focus on {selected_focus[2] if len(selected_focus) > 2 else "relationships"}
- Question 4: Focus on {selected_focus[3] if len(selected_focus) > 3 else "examples"}
- Question 5: Focus on a DIFFERENT unique aspect not covered above

OUTPUT FORMAT (PURE JSON array, no markdown, no backticks):
[
    {{"question": "Question 1 text (unique focus)...", "answer": "Answer 1...", "type": "{request.question_type}"}},
    {{"question": "Question 2 text (different focus)...", "answer": "Answer 2...", "type": "{request.question_type}"}},
    {{"question": "Question 3 text (different focus)...", "answer": "Answer 3...", "type": "{request.question_type}"}},
    {{"question": "Question 4 text (different focus)...", "answer": "Answer 4...", "type": "{request.question_type}"}},
    {{"question": "Question 5 text (different focus)...", "answer": "Answer 5...", "type": "{request.question_type}"}}
]

⚠️ REMINDER: Maximum variety! Each question must be completely different from any previous generation!"""
    
    new_cards = []
    generated_text = ""
    
    try:
        # 1. Try Groq
        if settings.GROQ_API_KEY:
            try:
                print("[Flashcards] Using Groq...")
                headers = {"Authorization": f"Bearer {settings.GROQ_API_KEY}", "Content-Type": "application/json"}
                # Create system message emphasizing variety
                system_message = f"""You are an expert educator creating educational flashcards. 
CRITICAL: Generate COMPLETELY DIFFERENT questions each time, even for the same topic.

VARIETY REQUIREMENTS:
- Never repeat the same or similar questions
- Vary question focus areas, phrasing, and formats
- Test different concepts, applications, and perspectives
- Use different question structures (What/How/Why/Compare/Describe/Calculate)
- Cover different aspects of the content each time

This is generation attempt #{int(time.time() % 100)} - ensure maximum variety!"""
                
                # Groq API parameters (check if frequency_penalty/presence_penalty are supported)
                # For now, using temperature and top_p which are definitely supported
                payload = {
                    "model": settings.GROQ_MODEL_NAME, 
                    "messages": [
                        {"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.95,  # Maximum variety - very high temperature
                    "top_p": 0.9,  # Nucleus sampling for diversity
                    "max_tokens": 1500  # Allow more tokens for variety
                }
                
                # Try to add frequency/presence penalties if Groq supports them
                # (Some API versions might support these)
                try:
                    payload["frequency_penalty"] = 0.5
                    payload["presence_penalty"] = 0.5
                except:
                    pass  # If not supported, skip
                resp = requests.post(settings.GROQ_API_ENDPOINT, headers=headers, json=payload, timeout=20)
                if resp.status_code == 200:
                    generated_text = resp.json()["choices"][0]["message"]["content"]
            except Exception as e:
                print(f"[Flashcards] Groq failed: {e}")

        # 2. Try Gemini if Groq failed (Not implemented in this refactor yet, skipping to Ollama/Mock)
        
        # 3. Fallback to Ollama
        if not generated_text:
            try:
                resp = requests.post(f"{settings.OLLAMA_BASE_URL}/api/generate", json={
                    "model": settings.OLLAMA_MODEL_PRIMARY,
                    "prompt": prompt,
                    "stream": False
                }, timeout=30)
                if resp.status_code == 200:
                    generated_text = resp.json().get("response", "")
            except Exception as e:
                print(f"[Flashcards] Ollama failed: {e}")

        # 4. Parse JSON and filter duplicates
        if generated_text:
            clean_text = generated_text.replace("```json", "").replace("```", "").strip()
            try:
                data = json.loads(clean_text)
                
                # Get existing question texts to check for duplicates
                existing_questions = set()
                if existing_flashcards:
                    for card in existing_flashcards:
                        if card.question:
                            # Normalize question for comparison (lowercase, remove extra spaces)
                            normalized = " ".join(card.question.lower().split())
                            existing_questions.add(normalized)
                
                # Check each generated question for uniqueness
                duplicate_count = 0
                for item in data:
                    question_text = item.get("question", "").strip()
                    if not question_text:
                        continue
                    
                    # Normalize for comparison
                    normalized_question = " ".join(question_text.lower().split())
                    
                    # Check if too similar to existing questions (simple substring check)
                    is_duplicate = False
                    for existing_q in existing_questions:
                        # Check if question is very similar (more than 70% overlap)
                        if normalized_question in existing_q or existing_q in normalized_question:
                            if len(normalized_question) > 20 and len(existing_q) > 20:  # Only for substantial questions
                                # More sophisticated: check word overlap
                                question_words = set(normalized_question.split())
                                existing_words = set(existing_q.split())
                                if len(question_words) > 0 and len(existing_words) > 0:
                                    overlap = len(question_words.intersection(existing_words)) / max(len(question_words), len(existing_words))
                                    if overlap > 0.7:  # More than 70% word overlap = duplicate
                                        is_duplicate = True
                                        duplicate_count += 1
                                        print(f"[Flashcards] Detected duplicate question: {question_text[:60]}...")
                                        break
                    
                    # Only add if not duplicate
                    if not is_duplicate:
                        new_cards.append({
                            "question_id": str(uuid.uuid4()),
                            "question": question_text,
                            "answer": item.get("answer", "Unknown"),
                            "question_type": item.get("type", request.question_type),
                            "days_until_review": 0
                        })
                    else:
                        # If duplicate found, try generating a replacement
                        print(f"[Flashcards] Skipping duplicate question, will be replaced by mock if needed")
                
                if duplicate_count > 0:
                    print(f"[Flashcards] Warning: {duplicate_count} duplicate(s) detected and filtered out")
                
            except json.JSONDecodeError as e:
                print(f"[Flashcards] JSON Decode Failed. Raw: {clean_text[:200]}")
                print(f"[Flashcards] Error: {e}")

        # 5. Mock Fallback
        if not new_cards:
            print("[Flashcards] AI generation failed. Using Mock Fallback.")
            for i in range(1, 6):
                new_cards.append({
                    "question_id": str(uuid.uuid4()),
                    "question": f"Mock Question {i} ({request.question_type})",
                    "answer": "Mock Answer",
                    "question_type": request.question_type,
                    "days_until_review": 0
                })
        
        # Save to DB instead of memory list
        # flashcards_db.extend(new_cards) 
        db_cards = []
        for card in new_cards:
            db_card = DBFlashcard(
                id=card["question_id"],
                user_id=current_user.id,
                question=card["question"],
                answer=card["answer"],
                question_type=card["question_type"],
                days_until_review=0,
                confidence=0.0
            )
            db.add(db_card)
            db_cards.append(db_card)
        
        db.commit()
        db.refresh(db_cards[0])  # Refresh one to ensure IDs are available
        
        # Sync each flashcard to EMS asynchronously (don't block response)
        for db_card in db_cards:
            try:
                # Get school_id from user if available
                school_id = getattr(current_user, 'school_id', None)

                ems_sync_result = await ems_sync.sync_flashcard(
                    gurukul_id=db_card.id,
                    student_email=current_user.email,
                    school_id=school_id,
                    question=db_card.question,
                    answer=db_card.answer,
                    question_type=db_card.question_type,
                    days_until_review=db_card.days_until_review,
                    confidence=db_card.confidence
                )
                
                if ems_sync_result:
                    logger.info(f"Synced flashcard {db_card.id} to EMS")
            except Exception as e:
                logger.error(f"Failed to sync flashcard {db_card.id} to EMS: {str(e)}")
                # Don't fail the request if sync fails
        
        return {"message": f"Generated {len(new_cards)} cards", "cards": new_cards}
        
    except Exception as e:
        print(f"[Flashcards] Critical Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("")
async def get_user_flashcards(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Get all flashcards for the current user"""
    flashcards = db.query(DBFlashcard).filter(
        DBFlashcard.user_id == current_user.id
    ).order_by(DBFlashcard.created_at.desc()).all()
    
    return [{
        "id": f.id,
        "question": f.question,
        "answer": f.answer,
        "question_type": f.question_type,
        "days_until_review": f.days_until_review,
        "confidence": f.confidence,
        "created_at": f.created_at.isoformat() if f.created_at else None
    } for f in flashcards]


@router.get("/download_pdf")
async def download_flashcards_pdf(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Generate and return PDF of all flashcards"""
    flashcards_db = db.query(DBFlashcard).filter(DBFlashcard.user_id == current_user.id).all()
    if not flashcards_db:
        raise HTTPException(status_code=404, detail="No flashcards found")
        
    try:
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", size=12)
        
        pdf.cell(200, 10, txt="Flashcard Questions", ln=1, align='C')
        pdf.ln(10)
        
        for i, card in enumerate(flashcards_db, 1):
            if isinstance(card, dict):
                q = card.get('question', '').encode('latin-1', 'replace').decode('latin-1')
                a = card.get('answer', '').encode('latin-1', 'replace').decode('latin-1')
            else:
                q = card.question.encode('latin-1', 'replace').decode('latin-1')
                a = card.answer.encode('latin-1', 'replace').decode('latin-1')
            
            pdf.set_font("Arial", 'B', 12)
            pdf.multi_cell(0, 10, f"Q{i}: {q}")
            pdf.set_font("Arial", '', 11)
            pdf.multi_cell(0, 10, f"A:  {a}")
            pdf.ln(5)
            
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
        pdf.output(tmp.name)
        tmp.close()
        
        return FileResponse(tmp.name, filename="practice_questions.pdf", media_type='application/pdf')
        
    except Exception as e:
        print(f"PDF Error: {e}")
        raise HTTPException(status_code=500, detail="Failed to generate PDF")

@router.get("/reviews/pending")
async def get_pending_reviews(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    # Fetch from DB for current user - only cards due for review (days_until_review <= 0)
    from datetime import datetime, timedelta
    from sqlalchemy import or_
    
    # Get cards that are due for review (days_until_review <= 0 or cards with no review schedule set yet)
    cards = db.query(DBFlashcard).filter(
        DBFlashcard.user_id == current_user.id,
        or_(
            DBFlashcard.days_until_review <= 0,
            DBFlashcard.days_until_review.is_(None)
        )
    ).order_by(DBFlashcard.created_at.desc()).all()
    
    # Convert to dict format expected by frontend
    return [
        {
            "question_id": card.id,
            "question": card.question,
            "answer": card.answer,
            "question_type": card.question_type,
            "days_until_review": card.days_until_review or 0
        }
        for card in cards
    ]

class ReviewAttempt(BaseModel):
    card_id: str
    difficulty: str # easy, medium, hard

@router.post("/reviews")
async def submit_review(
    attempt: ReviewAttempt,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    card = db.query(DBFlashcard).filter(
        DBFlashcard.id == attempt.card_id, 
        DBFlashcard.user_id == current_user.id
    ).first()
    
    if not card:
        raise HTTPException(status_code=404, detail="Card not found")
        
    # Simple Spaced Repetition Logic (Leitner System simplified)
    if attempt.difficulty == "easy":
        card.days_until_review = 7
        card.confidence = min(1.0, (card.confidence or 0) + 0.2)
    elif attempt.difficulty == "medium":
        card.days_until_review = 3
        card.confidence = min(1.0, (card.confidence or 0) + 0.1)
    else: # hard
        card.days_until_review = 1
        card.confidence = max(0.0, (card.confidence or 0) - 0.2)
        
    db.commit()
    return {"message": "Review logged", "next_review_days": card.days_until_review}

@router.get("/reviews/stats")
async def get_review_stats(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    total = db.query(DBFlashcard).filter(DBFlashcard.user_id == current_user.id).count()
    # Mock logic for categorization until we have real SRS fields fully populated
    mastered = db.query(DBFlashcard).filter(DBFlashcard.user_id == current_user.id, DBFlashcard.days_until_review > 5).count()
    learning = db.query(DBFlashcard).filter(DBFlashcard.user_id == current_user.id, DBFlashcard.days_until_review <= 5).count()
    
    return {
        "total_questions": total,
        "pending_reviews": learning, # For now assuming learning ones are due
        "learning": learning,
        "reviewing": 0,
        "mastered": mastered
    }
